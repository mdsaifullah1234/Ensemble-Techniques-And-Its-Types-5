{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "Design a pipeline that includes the following steps:\n",
    "• Use an automated feature selection method to identify the important features in the dataset.\n",
    "• Create a numerical pipeline that includes the following steps:\n",
    "• Impute the missing values in the numerical columns using the mean of the column values.\n",
    "• Scale the numerical columns using standardisation.\n",
    "• Create a categorical pipeline that includes the following steps:\n",
    "• Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "• One-hot encode the categorical columns.\n",
    "• Combine the numerical and categorical pipelines using a Column Transformer.\n",
    "• Use a Random Forest Classifier to build the final model.\n",
    "• Evaluate the accuracy of the model on the test dataset.\n",
    "Note: Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Automated feature selection\n",
    "feature_selection = SelectFromModel(RandomForestClassifier())\n",
    "\n",
    "# Numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Column transformer to combine numerical and categorical pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Final pipeline with feature selection and model\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit and evaluate the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "rf_classifier = RandomForestClassifier()\n",
    "lr_classifier = LogisticRegression()\n",
    "\n",
    "# Create pipeline with voting classifier\n",
    "pipeline = Pipeline([\n",
    "    ('voting', VotingClassifier(estimators=[\n",
    "        ('rf', rf_classifier),\n",
    "        ('lr', lr_classifier)\n",
    "    ], voting='hard'))\n",
    "])\n",
    "\n",
    "# Train pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "Two classifiers, Random Forest Classifier and Logistic Regression Classifier, are defined.\n",
    "A pipeline with a Voting Classifier is created, combining predictions from both classifiers.\n",
    "The pipeline is trained on the Iris dataset.\n",
    "Accuracy of the model on the test dataset is evaluated and printed.\n",
    "Interpretation:\n",
    "\n",
    "The pipeline combines predictions from Random Forest and Logistic Regression using a Voting Classifier.\n",
    "The accuracy score indicates how well the ensemble model performs on unseen data.\n",
    "Possible Improvements:\n",
    "\n",
    "Experiment with different combinations of classifiers in the voting ensemble.\n",
    "Tune hyperparameters of individual classifiers for better performance.\n",
    "Explore soft voting instead of hard voting for a weighted average of predicted probabilities.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
